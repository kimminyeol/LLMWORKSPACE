{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM은 방대한 텍스트 데이터를 학습하여 단어 간의 통계적 관계를 파악합니다.  입력된 텍스트를 토대로 다음에 올 단어를 예측하는 과정을 반복하며, 문장이나 문단을 생성합니다.  즉, 확률적 언어 모델을 기반으로, 가장 가능성 높은 텍스트를 생성하는 것입니다.  딥러닝 기반의 거대한 신경망을 사용합니다.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-f666bb2f-71cc-4fe0-a366-495c929c345d-0', usage_metadata={'input_tokens': 34, 'output_tokens': 105, 'total_tokens': 139, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# # API 키 환경 변수 설정 (선택 사항, 안전하게 관리하기 위해 권장됨)\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyAISc79ahkoEUGdwzkmYbEh0p2dKFP3w7E\"\n",
    "\n",
    "# 모델 로드\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=200,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")  # 환경 변수에서 API 키 가져오기\n",
    ")\n",
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"LLM은 어떤 원리로 작동하나요? 100자 이내로 설명해주세요.\"},\n",
    "]\n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'your-google-api-key'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"GOOGLE_API_KEY\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"LLM은 어떤 원리로 작동하나요? 100자 이내로 설명해주세요.\"},\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='LLM은 방대한 텍스트 데이터를 학습하여 단어 간의 통계적 관계를 파악합니다.  입력된 텍스트를 토대로 다음에 올 단어를 예측하는 과정을 반복하며, 문장이나 답변을 생성합니다.  이는 거대한 신경망을 기반으로 하며,  학습 데이터의 질과 양에 따라 성능이 크게 좌우됩니다.\\n', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-23c761ad-fcfc-4ccb-818e-e2b184929e8b-0', usage_metadata={'input_tokens': 34, 'output_tokens': 97, 'total_tokens': 131, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: Large Language Models (LLMs) leverage massive text datasets to learn language patterns, predicting and generating text using transformer architectures for efficient contextual understanding.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# Google Generative AI 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0,\n",
    "    max_output_tokens=100,\n",
    "    google_api_key=os.getenv(\"GOOGLE_API_KEY\")  # API 키 가져오기\n",
    ")\n",
    "\n",
    "# 요약 함수 정의\n",
    "def summarize_with_gemini(input_text: str) -> str:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that summarizes text.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Summarize the following text in less than 50 words:\\n\\n{input_text}\"}\n",
    "    ]\n",
    "    try:\n",
    "        # LLM 호출\n",
    "        response = llm.invoke(messages)\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "# 입력 텍스트\n",
    "text_to_summarize = \"\"\"\n",
    "Large Language Models (LLMs) work by using vast amounts of text data to learn patterns in language, enabling them to predict and generate text. \n",
    "They are based on transformer architectures, which allow them to process and understand the context of words in a sentence efficiently.\n",
    "\"\"\"\n",
    "\n",
    "# 요약 실행\n",
    "summary = summarize_with_gemini(text_to_summarize)\n",
    "print(f\"Summary: {summary}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
