{"cells":[{"cell_type":"markdown","metadata":{"id":"kFxyI2x6XaEq"},"source":["# **Settings**"]},{"cell_type":"markdown","metadata":{"id":"oZTHPKFKYyUf"},"source":["## **라이브러리 불러오기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MANUuizzXFS1"},"outputs":[],"source":["# 패키지 설치\n","!pip install langchain_google_genai faiss-cpu langchain_community langchain_openai"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"data":{"text/plain":["device(type='cpu')"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["device"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IX2IEHC8XLEp"},"outputs":[],"source":["# 라이브러리 불러오기\n","import os\n","import sys\n","from langchain_community.document_loaders.csv_loader import CSVLoader\n","from pathlib import Path\n","from langchain_openai import ChatOpenAI,OpenAIEmbeddings\n","from dotenv import load_dotenv\n","load_dotenv()\n","from langchain.document_loaders import CSVLoader\n","from langchain.text_splitter import TextSplitter\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","from langchain.prompts import PromptTemplate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBnXE-gMXTKo"},"outputs":[],"source":["# Colab 마운트\n","from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","# 경로 지정\n","os.chdir('/content/drive/MyDrive/RAG_LLM')"]},{"cell_type":"markdown","metadata":{"id":"mv14kYz9YwSD"},"source":["## **데이터 불러오기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xZwPt8uuZkpr"},"outputs":[],"source":["import pandas as pd\n","import ast\n","\n","# 데이터 불러오기\n","data = pd.read_csv('data/train_movie.csv')\n","\n","# 'movie_explain' 열을 리스트로 변환\n","data['movie_explain'] = data['movie_explain'].apply(ast.literal_eval)"]},{"cell_type":"markdown","metadata":{"id":"hFjkRASHZv81"},"source":["## **벡터DB 불러오기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SmfxUO5fZbZF"},"outputs":[],"source":["# 벡터스토어와 임베딩 불러오기\n","from langchain.vectorstores import FAISS\n","from langchain.embeddings import HuggingFaceEmbeddings\n","\n","embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n","vectorstore = FAISS.load_local(\"vectorstore_index_ratings_min10\", embeddings, allow_dangerous_deserialization=True)"]},{"cell_type":"markdown","metadata":{"id":"7IedUv3OaQeZ"},"source":["# **그래프 임베딩**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0mhDNVuaT8G"},"outputs":[],"source":["!pip install torch-geometric torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.0.0+cu118.html"]},{"cell_type":"markdown","metadata":{"id":"-ogxAKKrgz17"},"source":["## **Hetero 그래프**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbHO9atfaVUf"},"outputs":[],"source":["import torch\n","from torch_geometric.data import HeteroData\n","import re\n","import numpy as np\n","\n","# HeteroData 그래프 생성 (장르에서 '평점 평균'과 '시청 횟수'로 연결)\n","def create_genre_detailed_graph(user_id, viewing_data):\n","\n","    data_graph = HeteroData()\n","\n","    # 사용자 노드 추가\n","    data_graph[\"user\"].num_nodes = 1  # 단일 사용자\n","\n","    # 장르별 평점 및 시청 횟수 저장\n","    genre_ratings = {}\n","    genre_counts = {}\n","\n","    for record in viewing_data:\n","        try:\n","            # 예시: \"3186 (Drama) ratings: 4\"\n","            match = re.match(r\"\\d+\\s+\\((.*?)\\)\\s+ratings:\\s*(\\d+)\", record)\n","            if not match:\n","                print(f\"데이터 형식 오류: {record}\")\n","                continue\n","            genres, rating = match.groups()\n","            rating = int(rating)\n","\n","            for genre in genres.split(\"|\"):\n","                genre = genre.strip()\n","\n","                # 장르별 평점 누적 및 시청 횟수 증가\n","                if genre not in genre_ratings:\n","                    genre_ratings[genre] = []\n","                    genre_counts[genre] = 0\n","                genre_ratings[genre].append(rating)\n","                genre_counts[genre] += 1\n","        except Exception as e:\n","            print(f\"오류 발생: {e} (레코드: {record})\")\n","            continue\n","\n","    # 노드 추가\n","    genre_nodes = list(genre_ratings.keys())\n","    num_genres = len(genre_nodes)\n","\n","    data_graph[\"genre\"].num_nodes = num_genres\n","    data_graph[\"rating\"].num_nodes = num_genres\n","    data_graph[\"count\"].num_nodes = num_genres\n","\n","    # 장르별 특징(평점 평균, 시청 횟수) 계산\n","    avg_ratings = [np.mean(genre_ratings[genre]) for genre in genre_nodes]\n","    view_counts = [genre_counts[genre] for genre in genre_nodes]\n","\n","    # 노드 특성 추가 (평점 평균, 시청 횟수)\n","    data_graph[\"rating\"].x = torch.tensor(avg_ratings, dtype=torch.float).view(-1, 1)\n","    data_graph[\"count\"].x = torch.tensor(view_counts, dtype=torch.float).view(-1, 1)\n","\n","    # 사용자 → 장르 엣지 추가\n","    edge_index_user_genre = torch.tensor([[0] * num_genres, list(range(num_genres))], dtype=torch.long)\n","    data_graph[\"user\", \"has_preference\", \"genre\"].edge_index = edge_index_user_genre\n","\n","    # 장르 → 평점 연결\n","    edge_index_genre_rating = torch.tensor([list(range(num_genres)), list(range(num_genres))], dtype=torch.long)\n","    data_graph[\"genre\", \"has_avg_rating\", \"rating\"].edge_index = edge_index_genre_rating\n","\n","    # 장르 → 시청 횟수 연결\n","    edge_index_genre_count = torch.tensor([list(range(num_genres)), list(range(num_genres))], dtype=torch.long)\n","    data_graph[\"genre\", \"has_watch_count\", \"count\"].edge_index = edge_index_genre_count\n","\n","    return data_graph, genre_nodes"]},{"cell_type":"markdown","metadata":{"id":"7jcTT9VMg48n"},"source":["## **RGCN 모델**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5N4TTMHue52W"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.data import HeteroData\n","from torch_geometric.nn import RGCNConv, to_hetero\n","from tqdm import tqdm\n","import re\n","import math\n","\n","# RGCN 모델 정의 (homogeneous 모델로 시작)\n","class RGCN(torch.nn.Module):\n","    def __init__(self, in_channels, hidden_channels, out_channels, num_relations):\n","        super().__init__()\n","        self.conv1 = RGCNConv(in_channels, hidden_channels, num_relations)\n","        self.conv2 = RGCNConv(hidden_channels, out_channels, num_relations)\n","\n","    def forward(self, x, edge_index, edge_type):\n","        x = self.conv1(x, edge_index, edge_type)\n","        x = F.relu(x)\n","        x = self.conv2(x, edge_index, edge_type)\n","        return x"]},{"cell_type":"markdown","metadata":{"id":"CsdEhRGZg9b8"},"source":["## **이용자별로 그래프 임베딩**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QCHRlGzme86L"},"outputs":[],"source":["# 이용자별 그래프 임베딩\n","def compute_all_user_graph_embeddings(data, num_epochs=30, feature_dim=384, lr=0.01):\n","\n","    embeddings = []  # 임베딩을 저장할 리스트\n","\n","    for idx, row in tqdm(data.iterrows(), total=len(data), desc=\"Processing Users\"):\n","        user_id = row[\"UserId\"]\n","        viewing_data = row[\"movie_explain\"]\n","\n","        # 사용자별 장르 기반 그래프 생성 (graph만 추출)\n","        genre_graph, _ = create_genre_detailed_graph(user_id, viewing_data)\n","\n","        # 사용자별 그래프 임베딩 계산\n","        graph_embedding = compute_user_genre_graph_embedding(genre_graph,\n","                                                             num_epochs=num_epochs,\n","                                                             feature_dim=feature_dim,\n","                                                             lr=lr)\n","\n","        # detach()를 사용하여 텐서에서 numpy 변환 가능하게 함\n","        embeddings.append(graph_embedding.detach().numpy())\n","\n","    # 새 컬럼에 그래프 임베딩 저장\n","    data[\"graph_embedding\"] = embeddings\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OouY3oD7e_zf"},"outputs":[],"source":["import torch\n","import torch.nn.functional as F\n","from torch_geometric.nn import RGCNConv, to_hetero\n","\n","# 이용자-장르 그래프 임베딩\n","def compute_user_genre_graph_embedding(graph, num_epochs=30, feature_dim=128, lr=0.01):\n","    # 사용자(self-loop) 추가 → 사용자 노드가 업데이트 가능하도록 수정\n","    if \"user\" in graph.node_types and (\"user\", \"self_loop\", \"user\") not in graph.edge_types:\n","        num_users = graph[\"user\"].num_nodes\n","        if num_users > 0:\n","            self_loop_edges = torch.tensor([list(range(num_users)), list(range(num_users))], dtype=torch.long)\n","            graph[\"user\", \"self_loop\", \"user\"].edge_index = self_loop_edges\n","\n","    # 노드 초기 임베딩 설정 (각 타입별 랜덤 벡터 할당)\n","    for ntype in graph.node_types:\n","        num_nodes = graph[ntype].num_nodes\n","        graph[ntype].x = torch.randn((num_nodes, feature_dim))\n","\n","    # metadata 및 edge_type_dict 생성\n","    metadata = graph.metadata()  # (list(node_types), list(edge_types))\n","\n","    # edge_type_map: 각 엣지 타입에 대해 고유 id 부여\n","    edge_type_map = {etype: i for i, etype in enumerate(metadata[1])}\n","    edge_type_dict = {}\n","    for etype, edge_index in graph.edge_index_dict.items():\n","        edge_type_dict[etype] = torch.full((edge_index.size(1),), edge_type_map[etype],\n","                                           dtype=torch.long, device=edge_index.device)\n","\n","    # RGCN 모델 생성 및 heterogeneous 모델 변환\n","    num_relations = len(metadata[1])\n","    base_model = RGCN(in_channels=feature_dim, hidden_channels=512,\n","                      out_channels=feature_dim, num_relations=num_relations)\n","    model = to_hetero(base_model, metadata, aggr='sum')\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    # 학습 루프 (tqdm으로 경과 관찰)\n","    model.train()\n","    for epoch in range(num_epochs) :\n","        optimizer.zero_grad()\n","        out = model(graph.x_dict, graph.edge_index_dict, edge_type_dict)\n","        loss = sum(x.pow(2).mean() for x in out.values())  # 더미 loss\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 노드 임베딩을 평균 풀링하여 사용자 그래프 임베딩 생성\n","    graph_embeddings = []\n","    for ntype, x in out.items():\n","        pooled = x.mean(dim=0)  # 각 노드 타입별 평균 풀링\n","        graph_embeddings.append(pooled)\n","    graph_embedding = torch.stack(graph_embeddings, dim=0).mean(dim=0)  # 전체 평균\n","\n","    return graph_embedding"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s6nEsIPffNRR"},"outputs":[],"source":["# 사용자별 그래프 임베딩 계산\n","processed_data = compute_all_user_graph_embeddings(data, num_epochs=10, feature_dim=384, lr=0.01)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2t9l0sZ7fRJ8"},"outputs":[],"source":["import numpy as np\n","import faiss\n","\n","# DataFrame의 \"graph_embedding\" 컬럼에 저장된 384차원 임베딩들을 numpy 배열로 변환\n","graph_embeddings = np.stack(data[\"graph_embedding\"].values, axis=0).astype('float32')\n","\n","# 임베딩 차원 확인 (384여야 함)\n","dimension = graph_embeddings.shape[1]\n","\n","# FAISS 인덱스 생성 (L2 거리 기반)\n","faiss_index = faiss.IndexFlatL2(dimension)\n","faiss_index.add(graph_embeddings)\n","\n","# FAISS 인덱스 파일로 저장\n","faiss.write_index(faiss_index, \"raptor_graph_embeddings_faiss.index\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN9Ia0ovenysi+yup6Sqo0k","provenance":[]},"kernelspec":{"display_name":"kmy_env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"}},"nbformat":4,"nbformat_minor":0}
