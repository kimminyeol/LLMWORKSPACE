{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 시스템의 재정렬 (Reranking) 방법\n",
    "\n",
    "## 개요\n",
    "재정렬은 **RAG (Retrieval-Augmented Generation)** 시스템에서 검색된 문서의 **관련성**과 **품질**을 높이기 위한 단계이다. 초기 검색에서 찾은 문서의 순위를 다시 평가해, 최종 생성 단계에서 **가장 적합한 정보**가 우선적으로 사용되도록 한다.\n",
    "\n",
    "- 재정렬이 필요한 이유:\n",
    "초기 검색은 일반적으로 단순한 유사도 측정에 의존하므로, **문맥적 관련성**이나 **미묘한 의미 차이**를 놓칠 수 있다.  \n",
    "재정렬은 보다 정교한 평가를 통해 이러한 한계를 보완한다.\n",
    "\n",
    "\n",
    "## 주요 구성 요소\n",
    "- **초기 검색기**: FAISS 등 임베딩 기반 벡터 검색 도구 사용.  \n",
    "- **재정렬 모델**: 다음 중 한 가지 방법을 사용한다.  \n",
    "  - **LLM 기반**: 프롬프트를 이용해 문서의 관련성 점수를 평가.  \n",
    "  - **Cross-Encoder 기반**: 쿼리-문서 쌍을 입력해 정밀한 관련성 점수 부여.  \n",
    "- **점수 매기기 (Scoring)**: 재정렬을 위한 점수 계산.  \n",
    "- **정렬 및 선택**: 새로운 점수를 기준으로 상위 K개의 문서를 선택.  \n",
    "\n",
    "## 방법론\n",
    "1. **초기 검색**: 잠재적으로 관련 있는 문서를 검색.  \n",
    "2. **쌍 생성**: 검색된 문서와 쿼리의 쌍을 생성.  \n",
    "3. **점수 매기기**:  \n",
    "   - **LLM 방법**: LLM이 프롬프트를 통해 관련성 점수를 부여.  \n",
    "   - **Cross-Encoder 방법**: 쿼리-문서 쌍을 입력해 정밀한 점수 계산.  \n",
    "4. **정렬**: 새로운 점수를 기준으로 문서를 재정렬.  \n",
    "5. **상위 선택**: 상위 K개의 문서를 최종 선택.  \n",
    "\n",
    "\n",
    "## 장점\n",
    "- **정확성 향상**: LLM이나 Cross-Encoder를 통해 미묘한 관련성까지 반영.  \n",
    "- **잡음 감소**: 덜 중요한 문서를 제거해 생성 결과 품질을 높임.  \n",
    "- **유연성**: 데이터 특성이나 자원에 따라 다양한 방법 적용 가능.  \n",
    "\n",
    "## 결론\n",
    "재정렬은 **RAG 시스템의 성능**을 크게 향상시키는 핵심 기법이다.  \n",
    "특히 **LLM 기반**과 **Cross-Encoder 기반** 방법은 기존 검색만으로는 놓칠 수 있는 **세밀한 문맥 정보**를 반영하여, 생성 모델이 더 정확한 정보를 활용하도록 돕는다.  \n",
    "재정렬 기법은 검색과 생성 단계의 **정보 품질**을 높이는 필수 요소로 활용할 수 있다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/reranking-visualization.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/reranking_comparison.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers\n",
    "# ! pip install tf-keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the document's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: LLM based function to rerank the retrieved documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/rerank_llm.svg\" alt=\"rerank llm\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom reranking function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "class RatingScore(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
    "\n",
    "# 쿼리와 문서가 주어졌을 때 둘의 관련성을 점수로 파악하는 llm \n",
    "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"doc\"],\n",
    "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
    "        Query: {query}\n",
    "        Document: {doc}\n",
    "        Relevance Score:\"\"\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
    "    \n",
    "\n",
    "\n",
    "    # 점수가 매겨지고, 점수 순서대로 리랭크 되어 top n 만큼 문서가 출력된다. \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "        score = llm_chain.invoke(input_data).relevance_score\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0  # Default score if parsing fails\n",
    "        scored_docs.append((doc, score))\n",
    "    \n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage of the reranking function with a sample query relevant to the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top initial documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "goals. Policies should promote synergies between biodiversity conservation and climate \n",
      "action.  \n",
      "Chapter 10: Climate Change and Human Health  \n",
      "Health Impacts  \n",
      "Heat -Related Illnesses  \n",
      "Rising temper...\n",
      "\n",
      "Document 3:\n",
      "managed retreats.  \n",
      "Extreme Weather Events  \n",
      "Climate change is linked to an increase in the frequency and severity of extreme weather \n",
      "events, such as hurricanes, heatwaves, droughts, and heavy rainfa...\n",
      "Query: What are the impacts of climate change on biodiversity?\n",
      "\n",
      "리랭크된 문서:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
      "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
      "fisheries. Pr...\n",
      "\n",
      "Document 3:\n",
      "protection, and habitat creation.  \n",
      "Climate -Resilient Conservation  \n",
      "Conservation strategies must account for climate change impacts to be effective. This \n",
      "includes identifying climate refugia, areas...\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "# 초기 문서 반환 \n",
    "initial_docs = vectorstore.similarity_search(query, k=15)\n",
    "# 초기 문서를 리랭크 \n",
    "reranked_docs = rerank_documents(query, initial_docs)\n",
    "\n",
    "# print first 3 initial documents\n",
    "print(\"Top initial documents:\")\n",
    "for i, doc in enumerate(initial_docs[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"리랭크된 문서:\")\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom retriever based on our reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_3912/3925143671.py:2: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class CustomRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class CustomRetriever(BaseRetriever, BaseModel):\n",
    "    \n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    # 1차 검색 후 검새된 것들을 재정렬함\n",
    "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
    "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
    "\n",
    "\n",
    "custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_3912/546735038.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  result = qa_chain({\"query\": query})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What are the impacts of climate change on biodiversity?\n",
      "Answer: Climate change impacts biodiversity by shifting habitat ranges, changing species distributions, and affecting ecosystem functions. In terrestrial ecosystems, such as forests, grasslands, and deserts, these changes can lead to a loss of biodiversity and disrupt ecological balance. In marine ecosystems, rising sea temperatures, ocean acidification, and changing currents affect marine biodiversity, leading to species migration and changes in reproductive cycles, which can disrupt marine food webs and fisheries. Coral reefs, in particular, are highly sensitive to temperature and acidity changes, resulting in coral bleaching and mortality, which threaten biodiversity and fisheries.\n",
      "\n",
      "Relevant source documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
      "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
      "fisheries. Pr...\n"
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example that demonstrates why we should use reranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Retrieval Techniques\n",
      "==================================\n",
      "Query: what is the capital of france?\n",
      "\n",
      "Baseline Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "The capital of France is great.\n",
      "\n",
      "Document 2:\n",
      "The capital of France is beautiful.\n",
      "\n",
      "Advanced Retrieval Result:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_3912/3086860992.py:28: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  advanced_docs = custom_retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1:\n",
      "The capital of France is great.\n",
      "\n",
      "Document 2:\n",
      "The capital of France is beautiful.\n"
     ]
    }
   ],
   "source": [
    "chunks = [\n",
    "    \"The capital of France is great.\",\n",
    "    \"The capital of France is huge.\",\n",
    "    \"The capital of France is beautiful.\",\n",
    "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
    "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\", \n",
    "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
    "]\n",
    "docs = [Document(page_content=sentence) for sentence in chunks]\n",
    "\n",
    "\n",
    "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    print(\"Comparison of Retrieval Techniques\")\n",
    "    print(\"==================================\")\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    print(\"Baseline Retrieval Result:\")\n",
    "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
    "    for i, doc in enumerate(baseline_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "    print(\"\\nAdvanced Retrieval Result:\")\n",
    "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "    advanced_docs = custom_retriever.get_relevant_documents(query)\n",
    "    for i, doc in enumerate(advanced_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "\n",
    "query = \"what is the capital of france?\"\n",
    "compare_rag_techniques(query, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Cross Encoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/rerank_cross_encoder.svg\" alt=\"rerank cross encoder\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cross encoder class\n",
    "**Cross-Encoder** : Transformer 구조를 기반으로 쿼리 - 문서 쌍의 관련성을 평가하는 모델 \n",
    "- 쿼리와 문서를 하나의 입력 시퀀스로 결합하여 문맥을 고려한 높은 정확도의 관련성 점수 제공함 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kmy_env/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_3912/2986707392.py:3: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_3912/2986707392.py:3: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
      "  class CrossEncoderRetriever(BaseRetriever, BaseModel):\n"
     ]
    }
   ],
   "source": [
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
    "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
    "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "        \n",
    "        # 크로스 인코더에 넣을 초기 문서와 쿼리를 쌍으로 만듬\n",
    "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "        scores = self.cross_encoder.predict(pairs) # 점수 계산 \n",
    "        \n",
    "        # Sort documents by score\n",
    "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        raise NotImplementedError(\"Async retrieval not implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance and showcase over an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Question: What are the impacts of climate change on biodiversity?\n",
      "Answer: Climate change impacts biodiversity by altering terrestrial and marine ecosystems. It shifts habitat ranges, changes species distributions, and affects ecosystem functions, leading to a loss of biodiversity and disrupting ecological balance. In terrestrial ecosystems, such as forests, grasslands, and deserts, there are shifts in plant and animal species composition. Marine ecosystems are also highly vulnerable, with rising sea temperatures, ocean acidification, and changing currents affecting marine biodiversity, disrupting marine food webs and fisheries. These changes can lead to species migration and altered reproductive cycles.\n",
      "\n",
      "Relevant source documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "protection, and habitat creation.  \n",
      "Climate -Resilient Conservation  \n",
      "Conservation strategies must account for climate change impacts to be effective. This \n",
      "includes identifying climate refugia, areas...\n",
      "\n",
      "Document 3:\n",
      "goals. Policies should promote synergies between biodiversity conservation and climate \n",
      "action.  \n",
      "Chapter 10: Climate Change and Human Health  \n",
      "Health Impacts  \n",
      "Heat -Related Illnesses  \n",
      "Rising temper...\n",
      "\n",
      "Document 4:\n",
      "cultural perceptions.  \n",
      "Youth Engagement  \n",
      "Youth are vital stakeholders in climate action. Empowering young people through education, \n",
      "activism, and leadership opportunities can drive transformative c...\n",
      "\n",
      "Document 5:\n",
      "Local communities are often on the front lines of climate impacts and can be powerful agents \n",
      "of change. Community -based conservation projects involve residents in protecting and \n",
      "restoring natural r...\n"
     ]
    }
   ],
   "source": [
    "# Create the cross-encoder retriever\n",
    "cross_encoder_retriever = CrossEncoderRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    cross_encoder=cross_encoder,\n",
    "    k=10,  # Retrieve 10 documents initially\n",
    "    rerank_top_k=5  # Return top 5 after reranking\n",
    ")\n",
    "\n",
    "# Set up the LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Create the RetrievalQA chain with the cross-encoder retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
