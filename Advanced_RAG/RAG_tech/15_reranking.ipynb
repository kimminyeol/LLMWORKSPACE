{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 시스템의 재정렬(Reranking) 방법\n",
    "\n",
    "## 개요\n",
    "재정렬은 **검색 기반 생성(Retrieval-Augmented Generation, RAG)** 시스템에서 검색된 문서의 관련성과 품질을 향상시키기 위한 중요한 단계입니다. 초기 검색된 문서를 재평가하고 순서를 재조정하여, 생성 또는 프레젠테이션에 가장 적합한 정보를 우선시할 수 있도록 하는 과정입니다.\n",
    "\n",
    "## 동기\n",
    "RAG 시스템에서 재정렬을 사용하는 주된 이유는 초기 검색 방법의 한계를 극복하기 위함입니다. 초기 검색 방법은 간단한 유사도 측정에 의존하는 경우가 많아, 쿼리와 문서 간의 미묘한 관계를 파악하지 못할 수 있습니다. 재정렬 과정을 통해 보다 정교한 관련성 평가를 수행하고, 이를 통해 생성 단계에서 가장 적절한 정보가 활용될 수 있도록 합니다.\n",
    "\n",
    "## 주요 구성 요소\n",
    "재정렬 시스템은 일반적으로 다음과 같은 구성 요소를 포함합니다:\n",
    "\n",
    "1. **초기 검색기**: 보통 임베딩 기반의 유사도 검색을 수행하는 벡터 스토어.\n",
    "2. **재정렬 모델**: 다음 중 하나를 사용하여 관련성을 평가합니다.\n",
    "   - 대규모 언어 모델(LLM)을 사용한 관련성 점수 부여\n",
    "   - 관련성 평가에 특화된 Cross-Encoder 모델\n",
    "3. **점수 매기기 메커니즘(Scoring Mechanism)**: 문서에 관련성 점수를 부여하는 방법.\n",
    "4. **정렬 및 선택 로직**: 새로운 점수를 기준으로 문서를 재정렬하고 상위 문서를 선택하는 로직.\n",
    "\n",
    "## 방법론 세부 사항\n",
    "재정렬 과정은 일반적으로 다음 단계로 진행됩니다:\n",
    "\n",
    "1. **초기 검색**: 초기에는 잠재적으로 관련이 있는 문서를 검색하여 가져옵니다.\n",
    "2. **쌍 생성**: 각 검색된 문서와 쿼리의 쌍을 만듭니다.\n",
    "3. **점수 매기기**:\n",
    "   - **LLM 방법**: LLM에 프롬프트를 사용하여 문서의 관련성을 평가하도록 합니다.\n",
    "   - **Cross-Encoder 방법**: 쿼리-문서 쌍을 모델에 직접 입력하여 관련성을 평가합니다.\n",
    "4. **점수 해석**: 관련성 점수를 구문 분석하고 정규화합니다.\n",
    "5. **재정렬**: 새로운 관련성 점수에 따라 문서를 정렬합니다.\n",
    "6. **선택**: 재정렬된 리스트에서 상위 K개의 문서를 선택합니다.\n",
    "\n",
    "## 이 접근법의 장점\n",
    "재정렬은 여러 가지 이점을 제공합니다:\n",
    "\n",
    "1. **관련성 향상**: 더 정교한 모델을 사용함으로써, 미세한 관련성 요소까지 포착하여 높은 관련성을 보장합니다.\n",
    "2. **유연성**: 특정 요구사항과 자원에 따라 다양한 재정렬 방법을 적용할 수 있습니다.\n",
    "3. **문맥 품질 향상**: RAG 시스템에 더 관련성 높은 문서를 제공함으로써 생성 응답의 품질을 높입니다.\n",
    "4. **잡음 감소**: 덜 관련성 높은 정보를 필터링하고, 가장 적합한 콘텐츠에 집중하게 합니다.\n",
    "\n",
    "## 결론\n",
    "재정렬은 RAG 시스템에서 검색된 정보의 품질을 크게 향상시키는 강력한 기법입니다. LLM 기반 점수 부여 또는 특화된 Cross-Encoder 모델을 사용하더라도, 재정렬은 문서의 관련성을 더 정밀하고 정확하게 평가할 수 있게 합니다. 이는 곧 후속 작업의 성능 향상으로 이어지며, 고급 RAG 구현에서 필수적인 구성 요소로 작용합니다.\n",
    "\n",
    "LLM 기반과 Cross-Encoder 재정렬 방법 중에서 선택할 때는 정확도 요구 사항, 가용한 컴퓨팅 자원, 그리고 특정 응용 프로그램의 필요 사항을 고려할 필요가 있습니다. 두 접근 방식 모두 기본 검색 방법보다 상당한 개선을 제공하며, RAG 시스템의 전체적인 효율성을 높이는 데 기여합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/reranking-visualization.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/reranking_comparison.svg\" alt=\"rerank llm\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install sentence-transformers\n",
    "# ! pip install tf-keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the document's path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = encode_pdf(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: LLM based function to rerank the retrieved documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/rerank_llm.svg\" alt=\"rerank llm\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom reranking function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.docstore.document import Document\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "class RatingScore(BaseModel):\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of a document to a query.\")\n",
    "\n",
    "# 쿼리와 문서가 주어졌을 때 둘의 관련성을 점수로 파악하는 llm \n",
    "def rerank_documents(query: str, docs: List[Document], top_n: int = 3) -> List[Document]:\n",
    "    prompt_template = PromptTemplate(\n",
    "        input_variables=[\"query\", \"doc\"],\n",
    "        template=\"\"\"On a scale of 1-10, rate the relevance of the following document to the query. Consider the specific context and intent of the query, not just keyword matches.\n",
    "        Query: {query}\n",
    "        Document: {doc}\n",
    "        Relevance Score:\"\"\"\n",
    "    )\n",
    "    \n",
    "    llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "    llm_chain = prompt_template | llm.with_structured_output(RatingScore)\n",
    "    \n",
    "\n",
    "\n",
    "    # 점수가 매겨지고, 점수 순서대로 리랭크 되어 top n 만큼 문서가 출력된다. \n",
    "    scored_docs = []\n",
    "    for doc in docs:\n",
    "        input_data = {\"query\": query, \"doc\": doc.page_content}\n",
    "        score = llm_chain.invoke(input_data).relevance_score\n",
    "        try:\n",
    "            score = float(score)\n",
    "        except ValueError:\n",
    "            score = 0  # Default score if parsing fails\n",
    "        scored_docs.append((doc, score))\n",
    "    \n",
    "    reranked_docs = sorted(scored_docs, key=lambda x: x[1], reverse=True)\n",
    "    return [doc for doc, _ in reranked_docs[:top_n]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage of the reranking function with a sample query relevant to the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top initial documents:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "goals. Policies should promote synergies between biodiversity conservation and climate \n",
      "action.  \n",
      "Chapter 10: Climate Change and Human Health  \n",
      "Health Impacts  \n",
      "Heat -Related Illnesses  \n",
      "Rising temper...\n",
      "\n",
      "Document 3:\n",
      "managed retreats.  \n",
      "Extreme Weather Events  \n",
      "Climate change is linked to an increase in the frequency and severity of extreme weather \n",
      "events, such as hurricanes, heatwaves, droughts, and heavy rainfa...\n",
      "Query: What are the impacts of climate change on biodiversity?\n",
      "\n",
      "리랭크된 문서:\n",
      "\n",
      "Document 1:\n",
      "Climate change is altering terrestrial ecosystems by shifting habitat ranges, changing species \n",
      "distributions, and impacting ecosystem functions. Forests, grasslands, and deserts are \n",
      "experiencing shi...\n",
      "\n",
      "Document 2:\n",
      "protection, and habitat creation.  \n",
      "Climate -Resilient Conservation  \n",
      "Conservation strategies must account for climate change impacts to be effective. This \n",
      "includes identifying climate refugia, areas...\n",
      "\n",
      "Document 3:\n",
      "Coral reefs are highly sensitive to changes in temperature and acidity. Ocean acidification \n",
      "and warming waters contribute to coral bleaching and mortality, threatening biodiversity and \n",
      "fisheries. Pr...\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "# 초기 문서 반환 \n",
    "initial_docs = vectorstore.similarity_search(query, k=15)\n",
    "# 초기 문서를 리랭크 \n",
    "reranked_docs = rerank_documents(query, initial_docs)\n",
    "\n",
    "# print first 3 initial documents\n",
    "print(\"Top initial documents:\")\n",
    "for i, doc in enumerate(initial_docs[:3]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document\n",
    "\n",
    "\n",
    "# Print results\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"리랭크된 문서:\")\n",
    "for i, doc in enumerate(reranked_docs):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a custom retriever based on our reranker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom retriever class\n",
    "class CustomRetriever(BaseRetriever, BaseModel):\n",
    "    \n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str, num_docs=2) -> List[Document]:\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=30)\n",
    "        return rerank_documents(query, initial_docs, top_n=num_docs)\n",
    "\n",
    "\n",
    "# Create the custom retriever\n",
    "custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "\n",
    "# Create an LLM for answering questions\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Create the RetrievalQA chain with the custom retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=custom_retriever,\n",
    "    return_source_documents=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example that demonstrates why we should use reranking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Retrieval Techniques\n",
      "==================================\n",
      "Query: what is the capital of france?\n",
      "\n",
      "Baseline Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "The capital of France is great.\n",
      "\n",
      "Document 2:\n",
      "The capital of France is beautiful.\n",
      "\n",
      "Advanced Retrieval Result:\n",
      "\n",
      "Document 1:\n",
      "I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\n",
      "\n",
      "Document 2:\n",
      "Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
      "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\n"
     ]
    }
   ],
   "source": [
    "chunks = [\n",
    "    \"The capital of France is great.\",\n",
    "    \"The capital of France is huge.\",\n",
    "    \"The capital of France is beautiful.\",\n",
    "    \"\"\"Have you ever visited Paris? It is a beautiful city where you can eat delicious food and see the Eiffel Tower. \n",
    "    I really enjoyed all the cities in france, but its capital with the Eiffel Tower is my favorite city.\"\"\", \n",
    "    \"I really enjoyed my trip to Paris, France. The city is beautiful and the food is delicious. I would love to visit again. Such a great capital city.\"\n",
    "]\n",
    "docs = [Document(page_content=sentence) for sentence in chunks]\n",
    "\n",
    "\n",
    "def compare_rag_techniques(query: str, docs: List[Document] = docs) -> None:\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "    print(\"Comparison of Retrieval Techniques\")\n",
    "    print(\"==================================\")\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    \n",
    "    print(\"Baseline Retrieval Result:\")\n",
    "    baseline_docs = vectorstore.similarity_search(query, k=2)\n",
    "    for i, doc in enumerate(baseline_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "    print(\"\\nAdvanced Retrieval Result:\")\n",
    "    custom_retriever = CustomRetriever(vectorstore=vectorstore)\n",
    "    advanced_docs = custom_retriever.get_relevant_documents(query)\n",
    "    for i, doc in enumerate(advanced_docs):\n",
    "        print(f\"\\nDocument {i+1}:\")\n",
    "        print(doc.page_content)\n",
    "\n",
    "\n",
    "query = \"what is the capital of france?\"\n",
    "compare_rag_techniques(query, docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Cross Encoder models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/rerank_cross_encoder.svg\" alt=\"rerank cross encoder\" style=\"width:40%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the cross encoder class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "class CrossEncoderRetriever(BaseRetriever, BaseModel):\n",
    "    vectorstore: Any = Field(description=\"Vector store for initial retrieval\")\n",
    "    cross_encoder: Any = Field(description=\"Cross-encoder model for reranking\")\n",
    "    k: int = Field(default=5, description=\"Number of documents to retrieve initially\")\n",
    "    rerank_top_k: int = Field(default=3, description=\"Number of documents to return after reranking\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        # Initial retrieval\n",
    "        initial_docs = self.vectorstore.similarity_search(query, k=self.k)\n",
    "        \n",
    "        # Prepare pairs for cross-encoder\n",
    "        pairs = [[query, doc.page_content] for doc in initial_docs]\n",
    "        \n",
    "        # Get cross-encoder scores\n",
    "        scores = self.cross_encoder.predict(pairs)\n",
    "        \n",
    "        # Sort documents by score\n",
    "        scored_docs = sorted(zip(initial_docs, scores), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        # Return top reranked documents\n",
    "        return [doc for doc, _ in scored_docs[:self.rerank_top_k]]\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        raise NotImplementedError(\"Async retrieval not implemented\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an instance and showcase over an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the cross-encoder retriever\n",
    "cross_encoder_retriever = CrossEncoderRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    cross_encoder=cross_encoder,\n",
    "    k=10,  # Retrieve 10 documents initially\n",
    "    rerank_top_k=5  # Return top 5 after reranking\n",
    ")\n",
    "\n",
    "# Set up the LLM\n",
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "\n",
    "# Create the RetrievalQA chain with the cross-encoder retriever\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=cross_encoder_retriever,\n",
    "    return_source_documents=True\n",
    ")\n",
    "\n",
    "# Example query\n",
    "query = \"What are the impacts of climate change on biodiversity?\"\n",
    "result = qa_chain({\"query\": query})\n",
    "\n",
    "print(f\"\\nQuestion: {query}\")\n",
    "print(f\"Answer: {result['result']}\")\n",
    "print(\"\\nRelevant source documents:\")\n",
    "for i, doc in enumerate(result[\"source_documents\"]):\n",
    "    print(f\"\\nDocument {i+1}:\")\n",
    "    print(doc.page_content[:200] + \"...\")  # Print first 200 characters of each document"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
