{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 적응형 Retrieval-Augmented Generation (RAG) 시스템\n",
    "\n",
    "## 개요\n",
    "\n",
    "이 시스템은 다양한 쿼리 유형에 맞춰 검색 전략을 조정하는 고급 RAG(정보 검색 증강 생성) 접근 방식을 구현합니다. 여러 단계에서 대형 언어 모델(LLM)을 활용하여 사용자 쿼리에 대해 더 정확하고 관련성 높은, 그리고 상황에 맞는 응답을 제공하는 것을 목표로 합니다.\n",
    "\n",
    "## 동기\n",
    "\n",
    "기존의 RAG 시스템은 검색에 일관된 접근 방식을 취하는 경우가 많지만, 이는 다양한 쿼리 유형에 대해 비효율적일 수 있습니다. 본 적응형 시스템은 다양한 질문이 서로 다른 검색 전략을 필요로 한다는 이해에서 출발했습니다. 예를 들어, 사실 기반 쿼리는 정확하고 집중적인 검색이 효과적일 수 있지만, 분석적인 쿼리는 더 광범위하고 다양한 정보가 필요할 수 있습니다.\n",
    "\n",
    "## 주요 구성 요소\n",
    "\n",
    "1. **쿼리 분류기**: 쿼리 유형을 결정 (사실 기반, 분석적, 의견, 상황 기반)\n",
    "2. **적응형 검색 전략**: 서로 다른 쿼리 유형에 맞춘 네 가지 검색 전략\n",
    "   - 사실 기반 전략\n",
    "   - 분석적 전략\n",
    "   - 의견 전략\n",
    "   - 상황 기반 전략\n",
    "3. **LLM 통합**: 검색 및 순위 매김 과정에서 LLM을 활용\n",
    "4. **OpenAI GPT 모델**: 최종 응답 생성을 위해 검색된 문서를 컨텍스트로 사용\n",
    "\n",
    "## 방법 세부사항\n",
    "\n",
    "### 1. 쿼리 분류\n",
    "\n",
    "시스템은 우선 사용자의 쿼리를 다음 네 가지 유형 중 하나로 분류합니다:\n",
    "- **사실 기반**: 구체적이고 검증 가능한 정보를 찾는 질문\n",
    "- **분석적**: 포괄적 분석이나 설명을 필요로 하는 질문\n",
    "- **의견**: 주관적인 사안이나 다양한 관점을 찾는 질문\n",
    "- **상황 기반**: 사용자 특정 맥락에 의존하는 질문\n",
    "\n",
    "### 2. 적응형 검색 전략\n",
    "\n",
    "각 쿼리 유형에 따라 고유한 검색 전략이 실행됩니다:\n",
    "\n",
    "#### 사실 기반 전략\n",
    "- 정확성을 높이기 위해 LLM을 활용하여 쿼리를 개선합니다.\n",
    "- 개선된 쿼리를 바탕으로 문서를 검색합니다.\n",
    "- 검색된 문서를 LLM을 이용해 관련성에 따라 순위를 매깁니다.\n",
    "\n",
    "#### 분석적 전략\n",
    "- LLM을 사용하여 주요 쿼리에 대해 다양한 측면을 다룰 수 있도록 여러 하위 쿼리를 생성합니다.\n",
    "- 각 하위 쿼리에 대해 문서를 검색합니다.\n",
    "- 검색된 문서의 다양성을 유지하면서 최종 문서를 선정하도록 LLM을 활용합니다.\n",
    "\n",
    "#### 의견 전략\n",
    "- LLM을 사용하여 주제에 대한 다양한 관점을 식별합니다.\n",
    "- 각 관점을 대표하는 문서를 검색합니다.\n",
    "- 검색된 문서들 중 다양한 의견을 포함할 수 있도록 선택하여 제공합니다.\n",
    "\n",
    "#### 상황 기반 전략\n",
    "- LLM을 사용하여 사용자 특정 맥락을 쿼리에 포함시킵니다.\n",
    "- 맥락화된 쿼리에 따라 문서를 검색합니다.\n",
    "- 사용자 맥락을 고려하여 관련성과 맥락적 적합성에 따라 문서를 순위 매깁니다.\n",
    "\n",
    "### 3. LLM 기반 순위 매김\n",
    "\n",
    "검색 후 각 전략은 최종 문서 순위를 매기기 위해 LLM을 사용합니다. 이 단계는 가장 관련성 높고 적합한 문서들이 다음 단계로 넘어가도록 보장합니다.\n",
    "\n",
    "### 4. 응답 생성\n",
    "\n",
    "최종 검색된 문서들은 OpenAI GPT 모델로 전달되며, 이 모델은 쿼리와 제공된 컨텍스트를 기반으로 응답을 생성합니다.\n",
    "\n",
    "## 접근 방식의 이점\n",
    "\n",
    "1. **정확성 향상**: 쿼리 유형에 맞는 검색 전략을 통해 더 정확하고 관련성 높은 정보를 제공합니다.\n",
    "2. **유연성**: 시스템이 다양한 쿼리 유형에 맞게 적응하여 광범위한 사용자 요구를 처리할 수 있습니다.\n",
    "3. **상황 인식**: 특히 상황 기반 쿼리의 경우, 사용자 특정 정보를 통합하여 더 개인화된 응답을 제공합니다.\n",
    "4. **다양한 관점 제공**: 의견 기반 쿼리의 경우, 시스템이 여러 관점을 탐색하고 제시합니다.\n",
    "5. **포괄적 분석**: 분석적 전략을 통해 복잡한 주제에 대해 철저한 탐색을 수행합니다.\n",
    "\n",
    "## 결론\n",
    "\n",
    "본 적응형 RAG 시스템은 기존 RAG 접근 방식에 비해 큰 진전을 나타냅니다. 검색 전략을 동적으로 조정하고 과정 전반에 걸쳐 LLM을 활용함으로써, 다양한 사용자 쿼리에 대해 더 정확하고, 관련성 높은, 그리고 세밀한 응답을 제공하는 것을 목표로 합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/adaptive_retrieval.svg\" alt=\"adaptive retrieval\" style=\"width:100%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kmy_env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/anaconda3/envs/kmy_env/lib/python3.12/site-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.4.5, however version 2.5.2 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from langchain_core.retrievers import BaseRetriever\n",
    "from typing import Dict, Any\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the query classifer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class categories_options(BaseModel):\n",
    "        category: str = Field(description=\"The category of the query, the options are: Factual, Analytical, Opinion, or Contextual\", example=\"Factual\")\n",
    "\n",
    "# 사실, 분석, 의견, 맥락에 대한 쿼리를 분류하는 클래스\n",
    "class QueryClassifier:\n",
    "    def __init__(self):\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "        self.prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"Classify the following query into one of these categories: Factual, Analytical, Opinion, or Contextual.\\nQuery: {query}\\nCategory:\"\n",
    "        )\n",
    "        self.chain = self.prompt | self.llm.with_structured_output(categories_options)\n",
    "\n",
    "    def classify(self, query):\n",
    "        print(\"clasiffying query\")\n",
    "        return self.chain.invoke(query).category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Base Retriever class, such that the complex ones will inherit from it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색\n",
    "class BaseRetrievalStrategy:\n",
    "    def __init__(self, texts):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=800, chunk_overlap=0)\n",
    "        self.documents = text_splitter.create_documents(texts)\n",
    "        self.db = FAISS.from_documents(self.documents, self.embeddings)\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "\n",
    "    def retrieve(self, query, k=4):\n",
    "        return self.db.similarity_search(query, k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Factual retriever strategy -> 사실적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relevant_score(BaseModel):\n",
    "        score: float = Field(description=\"The relevance score of the document to the query\", example=8.0)\n",
    "\n",
    "class FactualRetrievalStrategy(BaseRetrievalStrategy):\n",
    "    def retrieve(self, query, k=4):\n",
    "        print(\"retrieving factual\")\n",
    "        # Use LLM to enhance the query -> 더 나은 정보 반환을 위한 사실적 쿼리로 향상시킴 \n",
    "        enhanced_query_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=\"Enhance this factual query for better information retrieval: {query}\"\n",
    "        )\n",
    "        query_chain = enhanced_query_prompt | self.llm\n",
    "        enhanced_query = query_chain.invoke(query).content\n",
    "        print(f'enhande query: {enhanced_query}')\n",
    "\n",
    "        # 새로운 쿼리로 유사도검색 \n",
    "        docs = self.db.similarity_search(enhanced_query, k=k*2)\n",
    "\n",
    "        # llm으로 reranking 함 \n",
    "        ranking_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"doc\"],\n",
    "            template=\"On a scale of 1-10, how relevant is this document to the query: '{query}'?\\nDocument: {doc}\\nRelevance score:\"\n",
    "        )\n",
    "        ranking_chain = ranking_prompt | self.llm.with_structured_output(relevant_score)\n",
    "\n",
    "        ranked_docs = []\n",
    "        print(\"ranking docs\")\n",
    "        for doc in docs:\n",
    "            input_data = {\"query\": enhanced_query, \"doc\": doc.page_content}\n",
    "            score = float(ranking_chain.invoke(input_data).score)\n",
    "            ranked_docs.append((doc, score))\n",
    "\n",
    "        # Sort by relevance score and return top k\n",
    "        ranked_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "        return [doc for doc, _ in ranked_docs[:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Analytical reriever strategy -> 분석적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectedIndices(BaseModel):\n",
    "    indices: List[int] = Field(description=\"Indices of selected documents\", example=[0, 1, 2, 3])\n",
    "\n",
    "class SubQueries(BaseModel):\n",
    "    sub_queries: List[str] = Field(description=\"List of sub-queries for comprehensive analysis\", example=[\"What is the population of New York?\", \"What is the GDP of New York?\"])\n",
    "\n",
    "class AnalyticalRetrievalStrategy(BaseRetrievalStrategy):\n",
    "    def retrieve(self, query, k=4):\n",
    "        print(\"retrieving analytical\")\n",
    "        # 분석적 질문이므로 쿼리를 서브 쿼리로 나누는 과정이 필요함 \n",
    "        sub_queries_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"k\"],\n",
    "            template=\"Generate {k} sub-questions for: {query}\"\n",
    "        )\n",
    "\n",
    "        llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "        sub_queries_chain = sub_queries_prompt | llm.with_structured_output(SubQueries)\n",
    "\n",
    "        input_data = {\"query\": query, \"k\": k}\n",
    "        sub_queries = sub_queries_chain.invoke(input_data).sub_queries\n",
    "        print(f'sub queries for comprehensive analysis: {sub_queries}')\n",
    "\n",
    "        all_docs = []\n",
    "        # 하위 질문에 대해 2가지씩 답변 \n",
    "        for sub_query in sub_queries:\n",
    "            all_docs.extend(self.db.similarity_search(sub_query, k=2))\n",
    "\n",
    "        # 다양하고 관련있는 문서들을 뽑아냄 \n",
    "        diversity_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"docs\", \"k\"],\n",
    "            template=\"\"\"Select the most diverse and relevant set of {k} documents for the query: '{query}'\\nDocuments: {docs}\\n\n",
    "            Return only the indices of selected documents as a list of integers.\"\"\"\n",
    "        )\n",
    "        diversity_chain = diversity_prompt | self.llm.with_structured_output(SelectedIndices)\n",
    "        docs_text = \"\\n\".join([f\"{i}: {doc.page_content[:50]}...\" for i, doc in enumerate(all_docs)])\n",
    "        input_data = {\"query\": query, \"docs\": docs_text, \"k\": k}\n",
    "        selected_indices_result = diversity_chain.invoke(input_data).indices\n",
    "        print(f'selected diverse and relevant documents')\n",
    "        \n",
    "        return [all_docs[i] for i in selected_indices_result if i < len(all_docs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Opinion retriever strategy -> 의견"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpinionRetrievalStrategy(BaseRetrievalStrategy):\n",
    "    def retrieve(self, query, k=3):\n",
    "        print(\"retrieving opinion\")\n",
    "        # llm을 통해 다양한 주제에 대한 관점을 먼저 식별함 \n",
    "        viewpoints_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"k\"],\n",
    "            template=\"Identify {k} distinct viewpoints or perspectives on the topic: {query}\"\n",
    "        )\n",
    "        viewpoints_chain = viewpoints_prompt | self.llm\n",
    "        input_data = {\"query\": query, \"k\": k}\n",
    "        viewpoints = viewpoints_chain.invoke(input_data).content.split('\\n')\n",
    "        print(f'viewpoints: {viewpoints}')\n",
    "\n",
    "        all_docs = []\n",
    "        for viewpoint in viewpoints:\n",
    "            all_docs.extend(self.db.similarity_search(f\"{query} {viewpoint}\", k=2))\n",
    "\n",
    "        # 다양한 관점을 사용하요 문서를 분류하고, 대표적인 문서를 선택함 \n",
    "        opinion_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"docs\", \"k\"],\n",
    "            template=\"Classify these documents into distinct opinions on '{query}' and select the {k} most representative and diverse viewpoints:\\nDocuments: {docs}\\nSelected indices:\"\n",
    "        )\n",
    "        opinion_chain = opinion_prompt | self.llm.with_structured_output(SelectedIndices)\n",
    "        \n",
    "        docs_text = \"\\n\".join([f\"{i}: {doc.page_content[:100]}...\" for i, doc in enumerate(all_docs)])\n",
    "        input_data = {\"query\": query, \"docs\": docs_text, \"k\": k}\n",
    "        selected_indices = opinion_chain.invoke(input_data).indices\n",
    "        print(f'selected diverse and relevant documents')\n",
    "        \n",
    "        return [all_docs[int(i)] for i in selected_indices.split() if i.isdigit() and int(i) < len(all_docs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Contextual retriever strategy -> 문맥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextualRetrievalStrategy(BaseRetrievalStrategy):\n",
    "    def retrieve(self, query, k=4, user_context=None):\n",
    "        print(\"retrieving contextual\")\n",
    "        # 사용자가 제공한 배경 정보를 쿼리에 포함하게 함 -> 사용자 쿼리의 맥락을 이해하고 사용자의 요구에 맞게 쿼리를 재구성함 \n",
    "        context_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"context\"],\n",
    "            template=\"Given the user context: {context}\\nReformulate the query to best address the user's needs: {query}\"\n",
    "        )\n",
    "        context_chain = context_prompt | self.llm\n",
    "        input_data = {\"query\": query, \"context\": user_context or \"No specific context provided\"}\n",
    "        contextualized_query = context_chain.invoke(input_data).content\n",
    "        print(f'contextualized query: {contextualized_query}')\n",
    "\n",
    "        # 재구성된 쿼리로 k의 제곱만큼 뽑아냄 \n",
    "        docs = self.db.similarity_search(contextualized_query, k=k*2)\n",
    "\n",
    "        # 문서와 쿼리의 관련성을 점수로 평가하여 정렬한다. \n",
    "        ranking_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\", \"context\", \"doc\"],\n",
    "            template=\"Given the query: '{query}' and user context: '{context}', rate the relevance of this document on a scale of 1-10:\\nDocument: {doc}\\nRelevance score:\"\n",
    "        )\n",
    "        ranking_chain = ranking_prompt | self.llm.with_structured_output(relevant_score)\n",
    "        print(\"ranking docs\")\n",
    "\n",
    "        ranked_docs = []\n",
    "        for doc in docs:\n",
    "            input_data = {\"query\": contextualized_query, \"context\": user_context or \"No specific context provided\", \"doc\": doc.page_content}\n",
    "            score = float(ranking_chain.invoke(input_data).score)\n",
    "            ranked_docs.append((doc, score))\n",
    "\n",
    "\n",
    "        # Sort by relevance score and return top k\n",
    "        ranked_docs.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        return [doc for doc, _ in ranked_docs[:k]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Adapive retriever class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveRetriever:\n",
    "    def __init__(self, texts: List[str]):\n",
    "        self.classifier = QueryClassifier()\n",
    "        self.strategies = {\n",
    "            \"Factual\": FactualRetrievalStrategy(texts),\n",
    "            \"Analytical\": AnalyticalRetrievalStrategy(texts),\n",
    "            \"Opinion\": OpinionRetrievalStrategy(texts),\n",
    "            \"Contextual\": ContextualRetrievalStrategy(texts)\n",
    "        }\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        category = self.classifier.classify(query)\n",
    "        strategy = self.strategies[category]\n",
    "        return strategy.retrieve(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define aditional retriever that inherits from langchain BaseRetriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_4145/4016186069.py:1: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
      "  class PydanticAdaptiveRetriever(BaseRetriever):\n",
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_4145/4016186069.py:1: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
      "  class PydanticAdaptiveRetriever(BaseRetriever):\n"
     ]
    }
   ],
   "source": [
    "class PydanticAdaptiveRetriever(BaseRetriever):\n",
    "    adaptive_retriever: AdaptiveRetriever = Field(exclude=True)\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return self.adaptive_retriever.get_relevant_documents(query)\n",
    "\n",
    "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
    "        return self.get_relevant_documents(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Adaptive RAG class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveRAG:\n",
    "    def __init__(self, texts: List[str]):\n",
    "        # 어떤 전략을 사용할지 선택 \n",
    "        adaptive_retriever = AdaptiveRetriever(texts)\n",
    "        # 선택된 전략을 사용하여 문서를 추출함\n",
    "        self.retriever = PydanticAdaptiveRetriever(adaptive_retriever=adaptive_retriever)\n",
    "        self.llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "        \n",
    "        # Create a custom prompt\n",
    "        prompt_template = \"\"\"Use the following pieces of context to answer the question at the end. \n",
    "        If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "\n",
    "        {context}\n",
    "\n",
    "        Question: {question}\n",
    "        Answer:\"\"\"\n",
    "        prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])\n",
    "        \n",
    "        # Create the LLM chain\n",
    "        self.llm_chain = prompt | self.llm\n",
    "        \n",
    "      \n",
    "\n",
    "    def answer(self, query: str) -> str:\n",
    "        # 어떤 질문인지 분류함 -> 분류에 맞게 카테고리와 전략을 추출 -> 이에 맞게 수정한 후 관련 문서를 추출함 \n",
    "        docs = self.retriever.get_relevant_documents(query)\n",
    "        input_data = {\"context\": \"\\n\".join([doc.page_content for doc in docs]), \"question\": query}\n",
    "        return self.llm_chain.invoke(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate use of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "texts = [\n",
    "    \"The Earth is the third planet from the Sun and the only astronomical object known to harbor life.\"\n",
    "    ]\n",
    "rag_system = AdaptiveRAG(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Showcase the four different types of queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gl/6qlsk6x94klgs54qzsg9q1jm0000gn/T/ipykernel_4145/3001477030.py:24: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  docs = self.retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clasiffying query\n",
      "retrieving factual\n",
      "enhande query: What is the average distance between the Earth and the Sun, and how does this distance vary throughout the year due to the Earth's elliptical orbit?\n",
      "ranking docs\n",
      "Answer: I don't know.\n",
      "clasiffying query\n",
      "retrieving analytical\n",
      "sub queries for comprehensive analysis: ['What is the average distance of the Earth from the Sun, and how does it vary throughout the year?', \"How does the Earth's elliptical orbit influence seasonal climate variations?\", \"What role does the Earth's axial tilt play in conjunction with its distance from the Sun in affecting climate?\", \"How do changes in the Earth's distance from the Sun over geological time scales (Milankovitch cycles) impact long-term climate patterns?\"]\n",
      "selected diverse and relevant documents\n",
      "Answer: I don't know.\n",
      "clasiffying query\n",
      "retrieving analytical\n",
      "sub queries for comprehensive analysis: ['What is the primordial soup theory and how does it explain the origin of life?', 'How does the panspermia hypothesis propose life began on Earth?', 'What role does the hydrothermal vent theory play in explaining the origin of life?', \"How do modern scientific experiments, like the Miller-Urey experiment, contribute to our understanding of life's origins?\"]\n",
      "selected diverse and relevant documents\n",
      "Answer: I don't know.\n",
      "clasiffying query\n",
      "retrieving analytical\n",
      "sub queries for comprehensive analysis: [\"What role does Earth's distance from the Sun play in maintaining temperatures suitable for life?\", \"How does Earth's position relative to other planets in the Solar System affect its gravitational stability and climate?\", \"In what ways does Earth's orbit shape the seasonal variations that are crucial for diverse ecosystems?\", \"How does the presence of the Moon, as a result of Earth's position in the Solar System, influence Earth's habitability?\"]\n",
      "selected diverse and relevant documents\n",
      "Answer: The Earth's position as the third planet from the Sun places it within the \"habitable zone,\" also known as the \"Goldilocks zone,\" where conditions are just right for liquid water to exist on the surface. This is crucial for life as we know it because water is a key ingredient for life. Additionally, Earth's position allows it to have a stable climate and temperature range that supports diverse ecosystems. The distance from the Sun also ensures that Earth receives enough sunlight for photosynthesis, which is essential for plant life and, by extension, the entire food chain.\n"
     ]
    }
   ],
   "source": [
    "factual_result = rag_system.answer(\"What is the distance between the Earth and the Sun?\").content\n",
    "print(f\"Answer: {factual_result}\")\n",
    "\n",
    "analytical_result = rag_system.answer(\"How does the Earth's distance from the Sun affect its climate?\").content\n",
    "print(f\"Answer: {analytical_result}\")\n",
    "\n",
    "opinion_result = rag_system.answer(\"What are the different theories about the origin of life on Earth?\").content\n",
    "print(f\"Answer: {opinion_result}\")\n",
    "\n",
    "contextual_result = rag_system.answer(\"How does the Earth's position in the Solar System influence its habitability?\").content\n",
    "print(f\"Answer: {contextual_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
