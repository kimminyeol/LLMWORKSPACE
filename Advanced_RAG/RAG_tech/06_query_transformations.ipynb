{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG 시스템에서의 향상된 검색을 위한 쿼리 변환 기법\n",
    "\n",
    "## 개요\n",
    "\n",
    "이 코드는 **Retrieval-Augmented Generation (RAG)** 시스템에서 검색 프로세스를 향상시키기 위해 다음의 세 가지 쿼리 변환 기법을 구현합니다:\n",
    "\n",
    "1. 쿼리 리라이팅(Query Rewriting)\n",
    "2. 스텝-백 프롬프팅(Step-back Prompting)\n",
    "3. 서브 쿼리 분해(Sub-query Decomposition)\n",
    "\n",
    "각 기법은 원래의 쿼리를 수정하거나 확장하여 검색된 정보의 관련성과 포괄성을 향상시키는 것을 목표로 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 동기\n",
    "\n",
    "RAG 시스템은 특히 복잡하거나 모호한 쿼리를 처리할 때 가장 관련성 있는 정보를 검색하는 데 어려움을 겪습니다. 이러한 쿼리 변환 기법들은 쿼리를 재구성하여 관련 문서와 더 잘 매칭되도록 하거나 더 포괄적인 정보를 검색할 수 있도록 돕는 역할을 합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 주요 구성 요소\n",
    "\n",
    "1. **쿼리 리라이팅(Query Rewriting)**: 쿼리를 더 구체적이고 세부적으로 다시 작성합니다.\n",
    "2. **스텝-백 프롬프팅(Step-back Prompting)**: 문맥을 더 잘 검색할 수 있도록 더 넓은 범위의 쿼리를 생성합니다.\n",
    "3. **서브 쿼리 분해(Sub-query Decomposition)**: 복잡한 쿼리를 더 간단한 하위 쿼리로 분해합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 기법별 세부 사항\n",
    "\n",
    "### 1. 쿼리 리라이팅(Query Rewriting)\n",
    "\n",
    "- **목적**: 쿼리를 더 구체적이고 세부적으로 만들어 관련 정보를 검색할 가능성을 높입니다.\n",
    "- **구현 방법**:\n",
    "  - GPT-4 모델과 사용자 정의 프롬프트 템플릿을 사용합니다.\n",
    "  - 원래의 쿼리를 가져와 더 구체적이고 세부적으로 재구성합니다.\n",
    "\n",
    "### 2. 스텝-백 프롬프팅(Step-back Prompting)\n",
    "\n",
    "- **목적**: 더 일반적이고 넓은 범위의 쿼리를 생성하여 관련된 배경 정보를 검색할 수 있게 합니다.\n",
    "- **구현 방법**:\n",
    "  - GPT-4 모델과 사용자 정의 프롬프트 템플릿을 사용합니다.\n",
    "  - 원래의 쿼리를 사용해 더 일반적인 “스텝-백” 쿼리를 생성합니다.\n",
    "\n",
    "### 3. 서브 쿼리 분해(Sub-query Decomposition)\n",
    "\n",
    "- **목적**: 복잡한 쿼리를 더 단순한 하위 쿼리로 분해하여 포괄적인 정보를 검색할 수 있게 합니다.\n",
    "- **구현 방법**:\n",
    "  - GPT-4 모델과 사용자 정의 프롬프트 템플릿을 사용합니다.\n",
    "  - 원래의 쿼리를 2~4개의 더 간단한 하위 쿼리로 분해합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 이러한 접근법의 이점\n",
    "\n",
    "1. **개선된 관련성**: 쿼리 리라이팅은 더 구체적이고 관련성 있는 정보 검색에 도움을 줍니다.\n",
    "2. **향상된 문맥성**: 스텝-백 프롬프팅은 더 넓은 문맥과 배경 정보를 검색할 수 있게 해줍니다.\n",
    "3. **포괄적인 결과**: 서브 쿼리 분해는 복잡한 쿼리의 다양한 측면을 다루는 정보를 검색하게 합니다.\n",
    "4. **유연성**: 각 기법은 독립적으로 또는 특정 사용 사례에 따라 조합하여 사용할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 구현 세부 사항\n",
    "\n",
    "- 모든 기법은 OpenAI의 GPT-4 모델을 사용해 쿼리를 변환합니다.\n",
    "- 사용자 정의 프롬프트 템플릿을 사용해 모델이 적절한 변환을 생성하도록 유도합니다.\n",
    "- 각 변환 기법에 대해 별도의 함수를 제공하여 기존 RAG 시스템에 쉽게 통합할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 예시 사용 사례\n",
    "\n",
    "코드는 다음의 예시 쿼리로 각 기법을 시연합니다:  \n",
    "**\"기후 변화가 환경에 미치는 영향은 무엇인가?\"**\n",
    "\n",
    "- **쿼리 리라이팅**은 이 질문을 온도 변화와 생물 다양성 등의 특정 측면을 포함하도록 확장합니다.\n",
    "- **스텝-백 프롬프팅**은 질문을 일반화하여 **\"기후 변화의 일반적인 영향은 무엇인가?\"**와 같은 형태로 변환합니다.\n",
    "- **서브 쿼리 분해**는 질문을 생물 다양성, 해양, 기후 패턴, 육상 환경과 같은 하위 질문으로 나눕니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 결론\n",
    "\n",
    "이러한 쿼리 변환 기법은 RAG 시스템의 검색 기능을 크게 향상시키는 강력한 방법을 제공합니다. 다양한 방식으로 쿼리를 재구성함으로써 검색된 정보의 관련성, 문맥성, 포괄성을 크게 향상시킬 수 있습니다. 이러한 기법은 과학 연구, 법률 분석 또는 종합적인 사실 검증 작업과 같이 쿼리가 복잡하거나 다면적인 도메인에서 특히 유용합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries and set environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - Query Rewriting: Reformulating queries to improve retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_write_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "# Create a prompt template for query rewriting\n",
    "# 더 자세하고 관련된 정보를 반환할 수 있도록 다시 쿼리를 재구성하도록 prompt 구성 \n",
    "query_rewrite_template = \"\"\"You are an AI assistant tasked with reformulating user queries to improve retrieval in a RAG system. \n",
    "Given the original query, rewrite it to be more specific, detailed, and likely to retrieve relevant information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Rewritten query:\"\"\"\n",
    "\n",
    "query_rewrite_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=query_rewrite_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for query rewriting\n",
    "query_rewriter = query_rewrite_prompt | re_write_llm\n",
    "\n",
    "# 재구성된 쿼리를 출력하는 함수 \n",
    "def rewrite_query(original_query):\n",
    "    response = query_rewriter.invoke(original_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: What are the impacts of climate change on the environment?\n",
      "\n",
      "Rewritten query: How does climate change affect various aspects of the environment, such as biodiversity, ecosystems, weather patterns, sea levels, and natural resources?\n"
     ]
    }
   ],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_query = \"What are the impacts of climate change on the environment?\"\n",
    "rewritten_query = rewrite_query(original_query)\n",
    "print(\"Original query:\", original_query)\n",
    "print(\"\\nRewritten query:\", rewritten_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Step-back Prompting: Generating broader queries for better context retrieval.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_back_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "\n",
    "# Create a prompt template for step-back prompting\n",
    "# 더 일반적이고 관련된 정보를 반환할 수 잇게 돕는 쿼리로 만든다. \n",
    "step_back_template = \"\"\"You are an AI assistant tasked with generating broader, more general queries to improve context retrieval in a RAG system.\n",
    "Given the original query, generate a step-back query that is more general and can help retrieve relevant background information.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "Step-back query:\"\"\"\n",
    "\n",
    "step_back_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=step_back_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for step-back prompting\n",
    "step_back_chain = step_back_prompt | step_back_llm\n",
    "\n",
    "def generate_step_back_query(original_query):\n",
    "    \"\"\"\n",
    "    Generate a step-back query to retrieve broader context.\n",
    "    \n",
    "    Args:\n",
    "    original_query (str): The original user query\n",
    "    \n",
    "    Returns:\n",
    "    str: The step-back query\n",
    "    \"\"\"\n",
    "    response = step_back_chain.invoke(original_query)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original query: What are the impacts of climate change on the environment?\n",
      "\n",
      "Step-back query: What are the general effects of climate change on natural systems and ecosystems?\n"
     ]
    }
   ],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_query = \"What are the impacts of climate change on the environment?\"\n",
    "step_back_query = generate_step_back_query(original_query)\n",
    "print(\"Original query:\", original_query)\n",
    "print(\"\\nStep-back query:\", step_back_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Sub-query Decomposition: Breaking complex queries into simpler sub-queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_query_llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o\", max_tokens=4000)\n",
    "\n",
    "# Create a prompt template for sub-query decomposition\n",
    "# 2~4개의 서브쿼리로 분해, 포괄적인 답변을 제공할 수 있다. few-shot 활용 \n",
    "subquery_decomposition_template = \"\"\"You are an AI assistant tasked with breaking down complex queries into simpler sub-queries for a RAG system.\n",
    "Given the original query, decompose it into 2-4 simpler sub-queries that, when answered together, would provide a comprehensive response to the original query.\n",
    "\n",
    "Original query: {original_query}\n",
    "\n",
    "example: What are the impacts of climate change on the environment?\n",
    "\n",
    "Sub-queries:\n",
    "1. What are the impacts of climate change on biodiversity?\n",
    "2. How does climate change affect the oceans?\n",
    "3. What are the effects of climate change on agriculture?\n",
    "4. What are the impacts of climate change on human health?\"\"\"\n",
    "\n",
    "\n",
    "subquery_decomposition_prompt = PromptTemplate(\n",
    "    input_variables=[\"original_query\"],\n",
    "    template=subquery_decomposition_template\n",
    ")\n",
    "\n",
    "# Create an LLMChain for sub-query decomposition\n",
    "subquery_decomposer_chain = subquery_decomposition_prompt | sub_query_llm\n",
    "\n",
    "def decompose_query(original_query: str):\n",
    "    response = subquery_decomposer_chain.invoke(original_query).content\n",
    "    sub_queries = [q.strip() for q in response.split('\\n') if q.strip() and not q.strip().startswith('Sub-queries:')]\n",
    "    return sub_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate on a use case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sub-queries:\n",
      "1. How does climate change affect weather patterns and extreme weather events?\n",
      "2. What are the impacts of climate change on polar ice caps and glaciers?\n",
      "3. How does climate change influence sea level rise and coastal areas?\n",
      "4. What are the effects of climate change on ecosystems and wildlife habitats?\n"
     ]
    }
   ],
   "source": [
    "# example query over the understanding climate change dataset\n",
    "original_query = \"What are the impacts of climate change on the environment?\"\n",
    "sub_queries = decompose_query(original_query)\n",
    "print(\"\\nSub-queries:\")\n",
    "for i, sub_query in enumerate(sub_queries, 1):\n",
    "    print(sub_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
