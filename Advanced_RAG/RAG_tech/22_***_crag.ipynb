{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 교정 RAG 프로세스: 동적 수정 기능을 갖춘 Retrieval-Augmented Generation\n",
    "\n",
    "## 개요\n",
    "\n",
    "교정 RAG(Retrieval-Augmented Generation) 프로세스는 정보 검색과 응답 생성을 더욱 발전시킨 시스템입니다. 표준 RAG 방식을 확장하여 **검색 과정을 동적으로 평가하고 수정**합니다. 이 시스템은 벡터 데이터베이스, 웹 검색, 언어 모델을 결합하여 사용자의 질문에 대해 **정확하고 컨텍스트에 맞는 응답**을 제공합니다.\n",
    "\n",
    "## 동기\n",
    "\n",
    "기존의 RAG 시스템은 정보 검색과 응답 생성에서 진전을 이루었으나, 여전히 **관련 없는 정보나 오래된 정보**를 반환하는 경우가 있습니다. 교정 RAG 프로세스는 이러한 문제를 해결하기 위해 설계되었으며 다음과 같은 기능을 제공합니다:\n",
    "\n",
    "1. 기존 지식 베이스 활용\n",
    "2. 검색된 정보의 관련성 평가\n",
    "3. 필요시 웹 검색을 통해 최신 정보 탐색\n",
    "4. 여러 출처에서 지식 정제 및 결합\n",
    "5. 가장 적합한 지식을 바탕으로 사람 같은 응답 생성\n",
    "\n",
    "## 주요 구성 요소\n",
    "\n",
    "1. **FAISS 인덱스**: 기존 지식 베이스의 효율적인 유사성 검색을 위한 벡터 데이터베이스\n",
    "2. **검색 평가기**: 검색된 문서의 쿼리 관련성을 평가\n",
    "3. **지식 정제**: 필요한 경우 문서에서 주요 정보를 추출\n",
    "4. **웹 검색 쿼리 재작성기**: 로컬 지식이 부족할 경우 웹 검색 쿼리를 최적화\n",
    "5. **응답 생성기**: 수집된 지식을 바탕으로 사람 같은 응답 생성\n",
    "\n",
    "## 방법 설명\n",
    "\n",
    "1. **문서 검색**:\n",
    "   - FAISS 인덱스를 사용하여 유사성 검색으로 관련 문서를 검색합니다.\n",
    "   - 상위 k개의 문서를 검색(기본 k=3).\n",
    "\n",
    "2. **문서 평가**:\n",
    "   - 각 문서에 대해 관련성 점수를 계산합니다.\n",
    "   - 최고 관련성 점수를 기준으로 적합한 조치를 결정합니다.\n",
    "\n",
    "3. **교정 지식 획득**:\n",
    "   - 높은 관련성(점수 > 0.7): 가장 관련성 높은 문서를 그대로 사용.\n",
    "   - 낮은 관련성(점수 < 0.3): 쿼리를 수정하여 웹 검색 수행.\n",
    "   - 중간 관련성(0.3 ≤ 점수 ≤ 0.7): 가장 관련성 높은 문서와 웹 검색 결과를 결합하여 사용.\n",
    "\n",
    "4. **적응형 지식 처리**:\n",
    "   - 웹 검색 결과: 주요 포인트만 추출하여 지식 정제.\n",
    "   - 중간 관련성: 원본 문서와 정제된 웹 검색 결과를 결합하여 사용.\n",
    "\n",
    "5. **응답 생성**:\n",
    "   - 언어 모델을 사용해 쿼리와 획득된 지식에 기반한 사람 같은 응답을 생성.\n",
    "   - 응답에 출처 정보를 포함하여 투명성을 보장.\n",
    "\n",
    "## 교정 RAG 접근의 이점\n",
    "\n",
    "1. **동적 수정**: 검색 정보의 품질에 맞춰 관련성과 정확성을 보장.\n",
    "2. **유연성**: 필요시 기존 지식과 웹 검색을 모두 활용.\n",
    "3. **정확성**: 정보를 사용하기 전에 관련성을 평가하여 고품질 응답 보장.\n",
    "4. **투명성**: 출처 정보를 제공하여 정보의 출처를 사용자에게 공개.\n",
    "5. **효율성**: 대규모 지식 베이스에서 빠르게 검색할 수 있는 벡터 검색 사용.\n",
    "6. **컨텍스트 이해**: 필요한 경우 여러 출처의 정보를 결합하여 포괄적인 응답 제공.\n",
    "7. **최신 정보 제공**: 오래된 로컬 지식을 대체하거나 보충할 수 있도록 웹에서 최신 정보 활용.\n",
    "\n",
    "## 결론\n",
    "\n",
    "교정 RAG 프로세스는 기존 RAG 접근 방식에서 한 단계 진화한 형태로, 검색 과정을 지능적으로 평가하고 수정하여 RAG 시스템의 한계를 극복합니다. 이 동적 접근 방식은 로컬 지식 베이스와 웹에서 가져온 가장 관련성 높고 최신 정보를 바탕으로 응답을 생성하여 **높은 정확도와 최신 정보가 필요한 응용 분야**에 적합합니다. 연구 지원, 동적 지식 베이스, 고급 질문-응답 시스템에서 특히 유용할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "\n",
    "<img src=\"../images/crag.svg\" alt=\"Corrective RAG\" style=\"width:80%; height:auto;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/kmy_env/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/opt/anaconda3/envs/kmy_env/lib/python3.12/site-packages/deepeval/__init__.py:49: UserWarning: You are using deepeval version 1.4.5, however version 1.4.7 is available. You should consider upgrading via the \"pip install --upgrade deepeval\" command.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..'))) # Add the parent directory to the path sicnce we work with notebooks\n",
    "from helper_functions import *\n",
    "from evaluation.evalute_rag import *\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Set the OpenAI API key environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv('OPENAI_API_KEY')\n",
    "from langchain.tools import DuckDuckGoSearchResults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define files path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/Understanding_Climate_Change.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x15b8b2f90>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore = encode_pdf(path)\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize OpenAI language model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=1000, temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = DuckDuckGoSearchResults()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define retrieval evaluator, knowledge refinement and query rewriter llm chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# 검색 평가기 입력 모델 정의\n",
    "class RetrievalEvaluatorInput(BaseModel):\n",
    "    # 문서의 쿼리에 대한 관련성 점수를 0에서 1 사이로 받음\n",
    "    relevance_score: float = Field(..., description=\"The relevance score of the document to the query. The score should be between 0 and 1.\")\n",
    "\n",
    "# 쿼리와 문서 관련성 점수 출력 함수 \n",
    "def retrieval_evaluator(query: str, document: str) -> float:\n",
    "    # 검색 결과에 대한 관련성 평가 프롬프트 생성\n",
    "    # 쿼리와 문서가 들어갔을 때 관련성 점수 매기는 프롬프트 \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"document\"],\n",
    "        template=\"On a scale from 0 to 1, how relevant is the following document to the query? Query: {query}\\nDocument: {document}\\nRelevance score:\"\n",
    "    )\n",
    "    # 프롬프트와 언어 모델을 연결하여 체인 생성, LLM의 출력은 RetrievalEvaluatorInput 구조에 맞춤\n",
    "    chain = prompt | llm.with_structured_output(RetrievalEvaluatorInput)\n",
    "    input_variables = {\"query\": query, \"document\": document}\n",
    "    result = chain.invoke(input_variables).relevance_score\n",
    "    return result\n",
    "\n",
    "\n",
    "# 지식 정제 입력 모델 정의\n",
    "class KnowledgeRefinementInput(BaseModel):\n",
    "    # 문서에서 주요 정보를 추출한 항목 리스트를 담음\n",
    "    key_points: str = Field(..., description=\"The document to extract key information from.\")\n",
    "\n",
    "# 문서를 넣었을 때 문서의 핵심 정보를 리스트로 추출함. \n",
    "def knowledge_refinement(document: str) -> List[str]:\n",
    "    # 문서에서 핵심 정보를 추출하는 프롬프트 생성\n",
    "    # 문서를 넣었을 때 핵심 정보를 추출함. \n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"document\"],\n",
    "        template=\"Extract the key information from the following document in bullet points:\\n{document}\\nKey points:\"\n",
    "    )\n",
    "    # 프롬프트와 언어 모델을 연결하여 체인 생성, LLM의 출력은 KnowledgeRefinementInput 구조에 맞춤\n",
    "    chain = prompt | llm.with_structured_output(KnowledgeRefinementInput)\n",
    "    input_variables = {\"document\": document}\n",
    "    result = chain.invoke(input_variables).key_points\n",
    "    return [point.strip() for point in result.split('\\n') if point.strip()]\n",
    "\n",
    "\n",
    "# 웹 검색용 쿼리 재작성 입력 모델 정의\n",
    "class QueryRewriterInput(BaseModel):\n",
    "    # 웹 검색에 적합한 형태로 수정된 쿼리\n",
    "    query: str = Field(..., description=\"The query to rewrite.\")\n",
    "\n",
    "# 쿼리를 넣었을 때 웹 검색에 적합하도록 쿼리를 재작성하는 프롬프트 \n",
    "def rewrite_query(query: str) -> str:\n",
    "    # 웹 검색에 적합하도록 쿼리를 재작성하는 프롬프트 생성\n",
    "    prompt = PromptTemplate(\n",
    "        input_variables=[\"query\"],\n",
    "        template=\"Rewrite the following query to make it more suitable for a web search:\\n{query}\\nRewritten query:\"\n",
    "    )\n",
    "    # 프롬프트와 언어 모델을 연결하여 체인 생성, LLM의 출력은 QueryRewriterInput 구조에 맞춤\n",
    "    chain = prompt | llm.with_structured_output(QueryRewriterInput)\n",
    "    input_variables = {\"query\": query}\n",
    "    return chain.invoke(input_variables).query.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 검색 결과 반환 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색 결과 넣으면 json형식으로, 검색 결과의 제목과 링크를 튜플로 반환 \n",
    "def parse_search_results(results_string: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"\n",
    "    검색 결과를 JSON 문자열로 받아, 각 검색 결과의 제목과 링크를 튜플로 반환하는 함수입니다.\n",
    "\n",
    "    Args:\n",
    "        results_string (str): JSON 형식의 검색 결과 문자열입니다.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, str]]: 검색 결과의 제목과 링크를 포함하는 튜플의 리스트를 반환합니다.\n",
    "                               만약 JSON 파싱에 실패할 경우, 빈 리스트를 반환합니다.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Attempt to parse the JSON string\n",
    "        results = json.loads(results_string)\n",
    "        # Extract and return the title and link from each result\n",
    "        return [(result.get('title', 'Untitled'), result.get('link', '')) for result in results]\n",
    "    except json.JSONDecodeError:\n",
    "        # Handle JSON decoding errors by returning an empty list\n",
    "        print(\"Error parsing search results. Returning empty list.\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define sub functions for the CRAG process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faiss 벡터 db에서 유사한 k개를 검색하여 내용을 리스트화함 \n",
    "def retrieve_documents(query: str, faiss_index: FAISS, k: int = 3) -> List[str]:\n",
    "    docs = faiss_index.similarity_search(query, k=k)\n",
    "    return [doc.page_content for doc in docs]\n",
    "\n",
    "# 쿼리와 문서 관련성 점수 출력 함수를 활용하여 모든 문서에 대한 점수 출력 \n",
    "def evaluate_documents(query: str, documents: List[str]) -> List[float]:\n",
    "\n",
    "    return [retrieval_evaluator(query, doc) for doc in documents]\n",
    "\n",
    "# 검색 내용의 핵심 내용, 제목, 링크 추출 \n",
    "def perform_web_search(query: str) -> Tuple[List[str], List[Tuple[str, str]]]:\n",
    "    # 검색할 형식에 맞춰 쿼리를 재작성 한 후 검색 -> 검색 내용의 핵심 내용을 추출, 검색 내용의 제목과 링크 추출 \n",
    "    rewritten_query = rewrite_query(query)\n",
    "    web_results = search.run(rewritten_query)\n",
    "    web_knowledge = knowledge_refinement(web_results)\n",
    "    sources = parse_search_results(web_results)\n",
    "    return web_knowledge, sources\n",
    "\n",
    "\n",
    "# 검색한 내용을 바탕으로 쿼리에 대해 응답하는 함수 \n",
    "def generate_response(query: str, knowledge: str, sources: List[Tuple[str, str]]) -> str:\n",
    "    # 쿼리, 검색 내용의 핵심 내용, 제목, 링크를 넣어 해당 내용을 바탕으로 쿼리에 대한 응답을 생성\n",
    "    # 정답의 마지막에 링크를 넣는 응답 \n",
    "    response_prompt = PromptTemplate(\n",
    "        input_variables=[\"query\", \"knowledge\", \"sources\"],\n",
    "        template=\"Based on the following knowledge, answer the query. Include the sources with their links (if available) at the end of your answer:\\nQuery: {query}\\nKnowledge: {knowledge}\\nSources: {sources}\\nAnswer:\"\n",
    "    )\n",
    "    input_variables = {\n",
    "        \"query\": query,\n",
    "        \"knowledge\": knowledge,\n",
    "        \"sources\": \"\\n\".join([f\"{title}: {link}\" if link else title for title, link in sources])\n",
    "    }\n",
    "    response_chain = response_prompt | llm\n",
    "    return response_chain.invoke(input_variables).content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRAG process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crag_process(query: str, faiss_index: FAISS) -> str:\n",
    "    \n",
    "    # 처리할 쿼리 지명 \n",
    "    print(f\"\\nProcessing query: {query}\")\n",
    "\n",
    "    # faiss에서 문서 반환 3개 \n",
    "    retrieved_docs = retrieve_documents(query, faiss_index)\n",
    "    # 관련도 점수 3개 \n",
    "    eval_scores = evaluate_documents(query, retrieved_docs)\n",
    "    \n",
    "    print(f\"\\nRetrieved {len(retrieved_docs)} documents\")\n",
    "    print(f\"Evaluation scores: {eval_scores}\")\n",
    "\n",
    "    # 최고 점수\n",
    "    max_score = max(eval_scores)\n",
    "    sources = []\n",
    "    \n",
    "    # 최고 점수가 0.7을 넘을 때 충분히 관련성이 높다고 생각하여 반환된 문서 그대로 사용 \n",
    "    # 0.3보다 낮을 때 웹서칭\n",
    "    # 그 사이면 반환된 문서의 중요한 정보만 뽑고, 검색한 문서의 중요한 정보만 뽑아서 둘을 합침. \n",
    "    if max_score > 0.7:\n",
    "        print(\"\\nAction: Correct - Using retrieved document\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        final_knowledge = best_doc\n",
    "        sources.append((\"Retrieved document\", \"\"))\n",
    "    elif max_score < 0.3:\n",
    "        print(\"\\nAction: Incorrect - Performing web search\")\n",
    "        final_knowledge, sources = perform_web_search(query)\n",
    "    else:\n",
    "        print(\"\\nAction: Ambiguous - Combining retrieved document and web search\")\n",
    "        best_doc = retrieved_docs[eval_scores.index(max_score)]\n",
    "        # Refine the retrieved knowledge\n",
    "        retrieved_knowledge = knowledge_refinement(best_doc)\n",
    "        web_knowledge, web_sources = perform_web_search(query)\n",
    "        final_knowledge = \"\\n\".join(retrieved_knowledge + web_knowledge)\n",
    "        sources = [(\"Retrieved document\", \"\")] + web_sources\n",
    "\n",
    "# 최종 결과 반환 \n",
    "    print(\"\\nFinal knowledge:\")\n",
    "    print(final_knowledge)\n",
    "\n",
    "# 검색한 링크와 제목 반환 \n",
    "    print(\"\\nSources:\")\n",
    "    for title, link in sources:\n",
    "        print(f\"{title}: {link}\" if link else title)\n",
    "\n",
    "# 최종 결과와 링크와 쿼리를 넣어 최종 응답 \n",
    "    print(\"\\nGenerating response...\")\n",
    "    response = generate_response(query, final_knowledge, sources)\n",
    "\n",
    "    print(\"\\nResponse generated\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query with high relevance to the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing query: What are the main causes of climate change?\n",
      "\n",
      "Retrieved 3 documents\n",
      "Evaluation scores: [0.9, 0.9, 0.6]\n",
      "\n",
      "Action: Correct - Using retrieved document\n",
      "\n",
      "Final knowledge:\n",
      "driven by human activities, particularly the emission of greenhou se gases.  \n",
      "Chapter 2: Causes of Climate Change  \n",
      "Greenhouse Gases  \n",
      "The primary cause of recent climate change is the increase in greenhouse gases in the \n",
      "atmosphere. Greenhouse gases, such as carbon dioxide (CO2), methane (CH4), and nitrous \n",
      "oxide (N2O), trap heat from the sun, creating a \"greenhouse effect.\" This effect is  essential \n",
      "for life on Earth, as it keeps the planet warm enough to support life. However, human \n",
      "activities have intensified this natural process, leading to a warmer climate.  \n",
      "Fossil Fuels  \n",
      "Burning fossil fuels for energy releases large amounts of CO2. This includes coal, oil, and \n",
      "natural gas used for electricity, heating, and transportation. The industrial revolution marked \n",
      "the beginning of a significant increase in fossil fuel consumption, which continues to rise \n",
      "today.  \n",
      "Coal\n",
      "\n",
      "Sources:\n",
      "Retrieved document\n",
      "\n",
      "Generating response...\n",
      "\n",
      "Response generated\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the main causes of climate change?\"\n",
    "result = crag_process(query, vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the main causes of climate change?\n",
      "Answer: The main causes of climate change are primarily driven by human activities that lead to the emission of greenhouse gases. The key factors include:\n",
      "\n",
      "1. **Greenhouse Gases**: The increase in greenhouse gases such as carbon dioxide (CO2), methane (CH4), and nitrous oxide (N2O) in the atmosphere is the primary cause of recent climate change. These gases trap heat from the sun, creating a \"greenhouse effect\" that is essential for maintaining life on Earth. However, human activities have intensified this natural process, resulting in a warmer climate.\n",
      "\n",
      "2. **Burning of Fossil Fuels**: The combustion of fossil fuels (coal, oil, and natural gas) for energy is a significant contributor to CO2 emissions. This includes their use in electricity generation, heating, and transportation. The industrial revolution marked a substantial increase in fossil fuel consumption, which has continued to rise, exacerbating climate change.\n",
      "\n",
      "3. **Deforestation and Land Use Changes**: While not explicitly mentioned in the provided knowledge, deforestation and changes in land use also contribute to climate change by reducing the number of trees that can absorb CO2 and altering the natural carbon cycle.\n",
      "\n",
      "These factors collectively lead to an increase in global temperatures and other climate-related changes.\n",
      "\n",
      "Sources: \n",
      "- Retrieved document (specific link not provided).\n"
     ]
    }
   ],
   "source": [
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example query with low relevance to the document\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how did harry beat quirrell?\"\n",
    "result = crag_process(query, vectorstore)\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Answer: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 내 생각\n",
    "- 반환된 문서가 쿼리랑 관련이 없다고 생각했을 때 웹서칭을 통해 최신 관련 정보를 검색하는 것\n",
    "- rag를 강화할 수 있는 큰 기술\n",
    "- 검색 방법 : https://bcho.tistory.com/1428"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kmy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
